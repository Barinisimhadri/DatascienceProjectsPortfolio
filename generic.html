<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic Page - Massively by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Intro -->
				<div id="intro">
					<h1>BARINI<br />
					THE DATA SCIENTIST<br />
					PORTFOLIO</h1>
					<p>"Transforming Data into Actionable Intelligence."
					</p>
					<ul class="actions">
						<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
					</ul>
				</div>

			<!-- Header -->
				<header id="header">
					<a href="index.html" class="logo">MORE</a>
				</header>

			<!-- Nav -->
				<nav id="nav">
					<ul class="links">
						<li><a href="index.html">Data Science</a></li>
						<li><a href="elements.html">Big Data</a></li>
						<li class="active"><a href="generic.html">CLOUD PLATFORMS</a></li>
					</ul>
					<ul class="icons">
						<li><a href="https://www.linkedin.com/in/barinisimhadri/" class="icon brands fa-linkedin"><span class="label">fa-linkedin</span></a></li>
						<li><a href="https://github.com/Barinisimhadri?tab=repositories" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
					</ul>
				</nav>

			<!-- Main -->
				<div id="main">

					<!-- Featured Post -->
						<article class="post featured">
							<header class="major">
								<h2><a href="#">CLOUD COMPUTING technologies<br />
								</a></h2>
								<p>AWS-(ATHENA,CLOUD WATCH,EC2,GLUE,IAM,KINESIS,LAMDA,S3,EMR,STEP FUNCTIONS,CLOUD9,CDK)<br />
								</p>
							</header>
							<a href="https://github.com/Barinisimhadri?tab=repositories" class="image main"><img src="images/combo.png" alt="" /></a>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri?tab=repositories" class="button large">VIEW PROJECTS</a></li>
							</ul>
						</article>

					<!-- Posts -->
					<section class="posts">
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/AWS_Athena_Covid_analysis">Big Data<br />
								Project to Learn AWS Athena</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/AWS_Athena_Covid_analysis" class="image fit"><img src="images/aws_athena_covid.png" alt="" /></a>
							<p>Amazon Athena simplifies data analysis in Amazon S3 through SQL queries without infrastructure setup. It's serverless, scales for big datasets, and supports various formats. Meanwhile, a data pipeline manages data from acquisition to storage, cleansing, transformation, and visualization, whether in real-time or batch, covering data handling and KPI display.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/AWS_Athena_Covid_analysis" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/AWS_ETLPipeline_Youtubedata">ETL pipeline on YouTube data<br />
								-Athena, Glue and Lamda</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/AWS_ETLPipeline_Youtubedata" class="image fit"><img src="images/youtubedata.png" alt="" /></a>
							<p>This project addresses challenges in cloud analytics migration like platform differences, security, and governance, especially vital in regulated industries. Utilizing Cloud-based Data Lake solutions, it organizes YouTube video data into storage phases for secure analysis, focusing on video categories and trending metrics, aiming to manage, streamline, and analyze data securely.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/AWS_ETLPipeline_Youtubedata" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/AWS_Hive_Ecommerce_Datawarehouse">Ecommerce-data-warehouse<br />
								in HIVE using AWS</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/AWS_Hive_Ecommerce_Datawarehouse" class="image fit"><img src="images/ecomm.png" alt="" /></a>
							<p>This big data project explores Hive's analytical features on vast datasets, utilizing the Adventure Works dataset from MySQL. Analyzing sales and customer demographics, it aims to derive insights such as age groups driving sales, discount ranges, customer contributions, purchasing patterns, and territory-wise sales adherence, employing Hive analytics with tools like Sqoop, Spark, and HDFS.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/AWS_Hive_Ecommerce_Datawarehouse" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/AWS_Lamda_Aurora_Website_Monitoring">Website<br />
								Monitoring</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/AWS_Lamda_Aurora_Website_Monitoring" class="image fit"><img src="images/website.png" alt="" /></a>
							<p>The project focuses on website monitoring, ensuring its availability and performance for end-users. It utilizes AWS services like EC2, Kinesis, Aurora MySQL, SNS, Lambda, and DynamoDB to create real-time monitoring. The agenda involves setting up Kinesis for data streaming, IAM roles, log streaming, Kinesis Analytics, Aurora MySQL, SNS, Secret Manager, Lambda for testing, DynamoDB for data storage, and real-time data streaming using Kinesis Analytics.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/AWS_Lamda_Aurora_Website_Monitoring" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/AWS_Neptune_Gremlin_GraphDatabase">Graph Database Modelling<br />
								- AWS Neptune and Gremlin</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/AWS_Neptune_Gremlin_GraphDatabase" class="image fit"><img src="images/neptune.png" alt="" /></a>
							<p>This project employs graph data modeling for an Airport Operator's analytics platform, addressing flight delay patterns, congested airports, and busiest connections. After data cleaning and modeling, it loads airline data into Amazon Neptune for efficient querying using Apache Gremlin, leveraging graph databases' advantages for faster association querying.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/AWS_Neptune_Gremlin_GraphDatabase" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>					
								<h2><a href="https://github.com/Barinisimhadri/AWS_Realtime_LogAnalytics">Log Analytics<br />
								</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/AWS_Realtime_LogAnalytics" class="image fit"><img src="images/realtime_log.png" alt="" /></a>
							<p>The project focuses on log analytics for multiple sources like websites, mobile devices, and sensors, enabling application availability tracking, fraud detection, and SLA monitoring. Using AWS Native Services, it parses and stores logs in S3, offering an end-to-end solution for batch and streaming data analytics. The solution ensures reliability, cost-effectiveness, scalability, and near real-time availability without extensive IT administration.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/AWS_Realtime_LogAnalytics" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/AWS_Realtime_Streaming_Twitter_NIFI_EC2">Twitter Sentiment Analysis<br />
								</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/AWS_Realtime_Streaming_Twitter_NIFI_EC2" class="image fit"><img src="images/sentiment.png" alt="" /></a>
							<p>The project focuses on real-time Twitter sentiment analysis, employing an AWS EC2 instance with Docker hosting tools like Apache Spark, NiFi, Kafka, Jupyter Lab, MongoDB, Plotly, and Dash. It involves supervised classification model creation, data extraction via Apache NiFi/Kafka, transformation, and loading into MongoDB, concluding with visualization using Python Plotly/Dash for graph and table app callback display.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/AWS_Realtime_Streaming_Twitter_NIFI_EC2" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/AWS_US_Accidentsa_realtime_Flink_Kinesis">Real-time Streaming<br />
								-Apache Flink & Kinesis</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/AWS_US_Accidentsa_realtime_Flink_Kinesis" class="image fit"><img src="images/kinesis.png" alt="" /></a>
							<p>This Project involves creating a real-time pipeline for actionable insights from high-value, time-sensitive data points, catering to scenarios like prioritized ticketing systems, unified government inquiries, and disaster management for resource allocation. It distinguishes perishable, time-critical data from historical, batch-reactive data, emphasizing preventive actions for perishable data and development in areas like business intelligence for reactive data.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/AWS_US_Accidentsa_realtime_Flink_Kinesis" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/AWS_SparkSQL_Scala_DataProcessing">Data Processing<br />
								-Spark-SQL using Scala</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/AWS_SparkSQL_Scala_DataProcessing" class="image fit"><img src="images/aws-spark_sql.png" alt="" /></a>
							<p>The project aims to teach Scala fundamentals, showcasing its multi-paradigm nature and JVM compatibility. It emphasizes creating RDDs, performing transformation operations, and analyzing a Movies dataset using RDDs and Spark SQL within Apache Spark, an open-source distributed processing solution for various data workloads, offering quick analytic queries and diverse workload support.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/AWS_SparkSQL_Scala_DataProcessing" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Batchprocessing_AWS_EMR_PySpark">Batch Processing<br />
								-AWS EMR & Pyspark</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Batchprocessing_AWS_EMR_PySpark" class="image fit"><img src="images/batchprocessing.png" alt="" /></a>
							<p>The project emphasizes Scala basics, demonstrating its multi-paradigm approach and compatibility with the JVM. It focuses on RDD creation, transformations, and analysis of a Movies dataset using Spark SQL in Apache Spark, facilitating quick analytics and supporting various data workloads efficiently.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Batchprocessing_AWS_EMR_PySpark" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Ecommerce_Aws_Analytics">Analytical Platform for<br />
								eCommerce Store using AWS</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Ecommerce_Aws_Analytics" class="image fit"><img src="images/ecomm.png" alt="" /></a>
							<p>This project focuses on eCommerce analytics using a dataset to build Batch and Real-time analytical pipelines. Batch processing involves data ingestion, Lake House architecture, and visualization with Amazon Kinesis, Glue, S3, and QuickSight to derive insights like unique visitors, abandoned carts, top categories, and brand marketing needs. Meanwhile, the Real-time channel focuses on detecting DDoS and Bot attacks using AWS Lambda, DynamoDB, CloudWatch, and AWS SNS for enhanced security measures in eCommerce platforms.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Ecommerce_Aws_Analytics" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>					
								<h2><a href="https://github.com/Barinisimhadri/ETL_Datapipeline_EMRcluster">Sales Data analysis<br />  
								S3,EMR,Hive,tableau</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/ETL_Datapipeline_EMRcluster" class="image fit"><img src="images/sales.png" alt="" /></a>
							<p>The project utilizes S3, EMR Hive, and Tableau for Sales Data Analysis, employing a SAAS data architecture with persistent storage in a Data Lake (HDFS). The process involves creating an S3 bucket, uploading sales data, setting up an EMR cluster, performing ETLs from external to final Hive tables, and connecting the final Hive table to Tableau for graph plotting. The project emphasizes S3's storage classes and features while highlighting EMR's usability, cost-effectiveness, elasticity, reliability, security, flexibility, and monitoring capabilities.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/ETL_Datapipeline_EMRcluster" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/ETLRedshift_glue_Stepfunctions">Orchestrate Redshift ETL<br />
								-Glue & Step Functions</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/ETLRedshift_glue_Stepfunctions" class="image fit"><img src="images/etlredshift.png" alt="" /></a>
							<p>This project centers on ETL processes, integrating and organizing data into a consistent data store for analytics and machine learning. It highlights ETL's role in data cleansing, organization, and accuracy improvement, focusing on Redshift as a data warehousing tool in the AWS cloud. Utilizing in-house AWS tools ensures end-to-end orchestration for loading, querying Redshift, and deriving business insights with guaranteed availability and durability provided by AWS.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/ETLRedshift_glue_Stepfunctions" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Pyspark_AWS_EMR_Athena">Remittance History<br />
								Analysis-EMR & Athena</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Pyspark_AWS_EMR_Athena" class="image fit"><img src="images/EMR_Athena.png" alt="" /></a>
							<p>The project aims to normalize transaction data by standardizing currency using historical exchange rates via API. It involves processing raw transaction logs for creditworthiness analysis in FinTech. Through Spark Transformations, it prepares the data in real-time, integrating a currency ticker API and loading processed data into Athena using Glue Crawler for subsequent analysis.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Pyspark_AWS_EMR_Athena" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Pyspark_Dataframe_Beginner">Pyspark Dataframe<br />
								Operations</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Pyspark_Dataframe_Beginner" class="image fit"><img src="images/dataframeadv.png" alt="" /></a>
							<p>This project focuses on advancing PySpark skills from RDDs to DataFrames, exploring various DataFrame operations and implementing transformation and action functions. It's part of a series aimed at delving deeper into Apache Spark, emphasizing code reuse across multiple workloads and its distributed processing capabilities.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Pyspark_Dataframe_Beginner" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Pyspark_Datapipeline_Hive_Cassandra">PySpark Integration<br />
								-Hive and Cassandra</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Pyspark_Datapipeline_Hive_Cassandra" class="image fit"><img src="images/cassandra.png" alt="" /></a>
							<p>This project in the PySpark series emphasizes PySpark's integration with Apache Cassandra and Apache Hive, focusing on ETL and ELT operations. It follows the sixth project, which concentrated on Amazon S3 and MySQL integration for similar operations. The tech stack includes Python, PySpark, and services like AWS EC2, Docker, Apache Cassandra, and Hive.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Pyspark_Datapipeline_Hive_Cassandra" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Pyspark_Datapipeline_SQL_S3">Pyspark<br />
								Integration</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Pyspark_Datapipeline_SQL_S3" class="image fit"><img src="images/pyspark_python.png" alt="" /></a>
							<p>This Project concentrates on integrating PySpark with Amazon S3 and MySQL for ETL and ELT operations, following the fifth project's introduction to PySpark SQL and various joins through a business case study. Apache Spark's capabilities in large data applications with code reuse across various workloads remain pivotal within this project's context.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Pyspark_Datapipeline_SQL_S3" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Pyspark_Hive_Datapipeline_Messaging">Building big data<br />
								pipeline on AWS</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Pyspark_Hive_Datapipeline_Messaging" class="image fit"><img src="images/aws-ETL.png" alt="" /></a>
							<p>This project involves collecting real-time COVID19 data every 5 minutes via NiFi, processing it in AWS data lake through NiFi, Kafka, and PySpark. The data is parsed from JSON to CSV, processed in PySpark via Kafka, stored in HDFS, orchestrated with Airflow, and visualized in Tableau to derive KPIs.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Pyspark_Hive_Datapipeline_Messaging" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Pyspark_Optimization_1">Pyspark<br />
								Optmization</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Pyspark_Optimization_1" class="image fit"><img src="images/price_optimisation.png" alt="" /></a>
							<p>In this PySpark project delves into Spark Optimization techniques, aiming to enhance resource utilization and job execution speed. It emphasizes modifying Spark settings, implementing Catalyst optimization, and optimizing file formats for improved performance in a distributed system like Apache Spark, following the ninth project focused on partitioning data structures.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Pyspark_Optimization_1" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Snowflake_Datapipeline_Kinesis_Airflow">Snowflake Data Pipeline<br />
								-Kinesis & Airflow</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Snowflake_Datapipeline_Kinesis_Airflow" class="image fit"><img src="images/kinesis.png" alt="" /></a>
							<p>This Snowflake Project involves building a data pipeline from EC2 logs to storage in Snowflake and S3 post-transformation using Airflow DAGs. It follows an introduction to Snowflake components in the first project, showcasing Snowflake's cloud-based, versatile, shared-disk, and shared-nothing architecture. Snowflake's service manages maintenance, updates, and utilizes MPP compute clusters for query execution.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Snowflake_Datapipeline_Kinesis_Airflow" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Snowflake_Realtime_Warehouse">Snowflake Real Time<br />
								Data Warehouse</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Snowflake_Realtime_Warehouse" class="image fit"><img src="images/snowflake_datawarehouse.png" alt="" /></a>
							<p>This project focuses on Snowflake's architecture, emphasizing its cloud-based, shared-disk, and shared-nothing design. It covers various Snowflake components such as Warehouse, Database, Schema, Table, View, Stored Procedure, Snowpipe, Stream, Task, and Time Travel, showcasing its service entirely operating on public cloud infrastructures and managing ongoing maintenance, administration, and updates.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Snowflake_Realtime_Warehouse" class="button">View Project</a></li>
							</ul>
						</article>
						<article>
							<header>
								<h2><a href="https://github.com/Barinisimhadri/Snowflake_SCD">slowly changing<br />
								dimensions-Snowflake</a></h2>
							</header>
							<a href="https://github.com/Barinisimhadri/Snowflake_SCD" class="image fit"><img src="images/snowflake_scd.png" alt="" /></a>
							<p>In this Snowflake project, different Slowly Changing Dimension (SCD) techniques - Type 0, Type 1, Type 2, and Type 3 - are implemented. Snowflake's Data Warehouse capabilities and ETL support are utilized to manage and monitor historical and current data changes within dimensions like customer, geography, and employee, aligning them with SCD methodologies in the context of a data warehouse.</p>
							<ul class="actions special">
								<li><a href="https://github.com/Barinisimhadri/Snowflake_SCD" class="button">View Project</a></li>
							</ul>
						</article>
					</section>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<section>
						<form method="post" action="#">
							<div class="fields">
								<div class="field">
									<label for="name">Name</label>
									<input type="text" name="name" id="name" />
								</div>
								<div class="field">
									<label for="email">Email</label>
									<input type="text" name="email" id="email" />
								</div>
								<div class="field">
									<label for="message">Message</label>
									<textarea name="message" id="message" rows="3"></textarea>
								</div>
							</div>
							<ul class="actions">
								<li><input type="submit" value="Send Message" /></li>
							</ul>
						</form>
					</section>
					<section class="split contact">
						<section class="alt">
							<h3>location:</h3>
							<p>Chicago,IL<br />
							</p>
						</section>
						<section>
							<h3>Email:</h3>
							<p><a href="#">barinisimhadri06@gmail.com</a></p>
						</section>
						<section>
							<h3>Social:</h3>
							<ul class="icons alt">
								<li><a href="https://www.linkedin.com/in/barinisimhadri/" class="icon brands fa-linkedin"><span class="label">fa-linkedin</span></a></li>
								<li><a href="https://github.com/Barinisimhadri?tab=repositories" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
							</ul>
						</section>
					</section>
				</footer>

			<!-- Copyright -->
				<div id="copyright">
					<ul><li>&copy;</li><li><a href="https://html5up.net"></a></li></ul>
				</div>

		</div>

	<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.scrollex.min.js"></script>
		<script src="assets/js/jquery.scrolly.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>

</body>
</html>